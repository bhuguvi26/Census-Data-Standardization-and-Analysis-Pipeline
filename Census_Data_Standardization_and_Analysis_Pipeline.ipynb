{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHMb4lGDAEipjbX0TiWCxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhuguvi26/Census-Data-Standardization-and-Analysis-Pipeline/blob/main/Census_Data_Standardization_and_Analysis_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xLxKl6dihA-",
        "outputId": "ce188300-4f38-493c-acf9-898da0ae1a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloudflared: Text file busy\n",
            "== Missing data BEFORE (%) ==\n",
            "District code                    0.00\n",
            "State_UT                         0.00\n",
            "District                         0.00\n",
            "Population                       4.69\n",
            "Male                             4.69\n",
            "                                 ... \n",
            "Power_Parity_Rs_330000_425000    5.16\n",
            "Power_Parity_Rs_425000_545000    4.69\n",
            "Power_Parity_Rs_330000_545000    3.59\n",
            "Power_Parity_Above_Rs_545000     4.69\n",
            "Total_Power_Parity               5.00\n",
            "Length: 118, dtype: float64\n",
            "\n",
            "== Missing data AFTER (%) ==\n",
            "District code                    0.00\n",
            "State_UT                         0.00\n",
            "District                         0.00\n",
            "Population                       0.16\n",
            "Male                             4.69\n",
            "                                 ... \n",
            "Power_Parity_Rs_330000_425000    5.16\n",
            "Power_Parity_Rs_425000_545000    4.69\n",
            "Power_Parity_Rs_330000_545000    3.59\n",
            "Power_Parity_Above_Rs_545000     4.69\n",
            "Total_Power_Parity               5.00\n",
            "Length: 118, dtype: float64\n",
            "\n",
            "== Sample of processed data ==\n",
            "   District code           State_UT     District  Population      Male  \\\n",
            "0              1  Jammu and Kashmir      Kupwara    870354.0  474190.0   \n",
            "1              2  Jammu and Kashmir       Badgam    753745.0       NaN   \n",
            "2              3  Jammu and Kashmir  Leh(Ladakh)    133487.0   78971.0   \n",
            "3              4             Ladakh       Kargil    140802.0       NaN   \n",
            "4              5  Jammu and Kashmir        Punch    476835.0  251899.0   \n",
            "\n",
            "     Female  Literate  Literate_Male  Literate_Female      SC  ...  \\\n",
            "0  396164.0  439654.0       282823.0         156831.0  1048.0  ...   \n",
            "1  355704.0  335649.0       207741.0         127908.0     NaN  ...   \n",
            "2   54516.0   93770.0        62834.0          30936.0   488.0  ...   \n",
            "3   63017.0   86236.0        56301.0          29935.0    18.0  ...   \n",
            "4  224936.0  261724.0       163333.0          98391.0   556.0  ...   \n",
            "\n",
            "   Power_Parity_Rs_90000_150000  Power_Parity_Rs_45000_150000  \\\n",
            "0                          94.0                         588.0   \n",
            "1                         126.0                         562.0   \n",
            "2                          46.0                         122.0   \n",
            "3                          27.0                         114.0   \n",
            "4                          78.0                         346.0   \n",
            "\n",
            "   Power_Parity_Rs_150000_240000  Power_Parity_Rs_240000_330000  \\\n",
            "0                           71.0                          101.0   \n",
            "1                           72.0                           89.0   \n",
            "2                           15.0                           22.0   \n",
            "3                           12.0                           18.0   \n",
            "4                           35.0                           50.0   \n",
            "\n",
            "   Power_Parity_Rs_150000_330000  Power_Parity_Rs_330000_425000  \\\n",
            "0                          172.0                           74.0   \n",
            "1                          161.0                           96.0   \n",
            "2                            NaN                           20.0   \n",
            "3                           30.0                           19.0   \n",
            "4                           85.0                           59.0   \n",
            "\n",
            "   Power_Parity_Rs_425000_545000  Power_Parity_Rs_330000_545000  \\\n",
            "0                           10.0                           84.0   \n",
            "1                           28.0                          124.0   \n",
            "2                            NaN                            NaN   \n",
            "3                            3.0                           22.0   \n",
            "4                            8.0                           67.0   \n",
            "\n",
            "   Power_Parity_Above_Rs_545000  Total_Power_Parity  \n",
            "0                          15.0              1119.0  \n",
            "1                          18.0              1066.0  \n",
            "2                          17.0               242.0  \n",
            "3                           7.0               214.0  \n",
            "4                          12.0               629.0  \n",
            "\n",
            "[5 rows x 118 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-30 22:31:37.138 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data uploaded to MongoDB successfully.\n",
            "‚úÖ Data uploaded to SQLite with dimensions and constraints.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-30 22:31:37.306 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-11-30 22:31:37.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.309 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.322 Session state does not function when running a script without `streamlit run`\n",
            "2025-11-30 22:31:37.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.327 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.328 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.329 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.334 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.345 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.356 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.367 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.374 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-11-30 22:31:37.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Starting Streamlit & Cloudflared...\n",
            "üåê Public URL: https://boys-specials-photographer-creature.trycloudflare.com\n",
            "‚úÖ Open this URL to view the Streamlit dashboard.\n",
            "‚ÑπÔ∏è To stop: Runtime ‚Üí Interrupt execution, or run:\n",
            "    streamlit_proc.terminate(); cloudflared_proc.terminate()\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =========================\n",
        "# Colab Single-Cell Runner\n",
        "# =========================\n",
        "\n",
        "# 1) Install dependencies (Cloudflared avoids ngrok auth token requirement)\n",
        "!pip -q install pandas requests python-docx pymongo streamlit openpyxl\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "!chmod +x cloudflared\n",
        "\n",
        "# 2) MongoDB Atlas credentials (provided)\n",
        "MONGO_URI = \"mongodb+srv://bhuvan:12345@cluster0.obh30fm.mongodb.net/censusdb?retryWrites=true&w=majority\"\n",
        "\n",
        "# 3) Write full pipeline + Streamlit dashboard to app.py\n",
        "#    IMPORTANT: use r''' ... ''' for a raw, triple-quoted multi-line string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from docx import Document\n",
        "from pymongo import MongoClient\n",
        "import sqlite3\n",
        "import streamlit as st\n",
        "\n",
        "# =============================\n",
        "# CONFIGURATION\n",
        "# =============================\n",
        "EXCEL_URL = \"https://raw.githubusercontent.com/bhuguvi26/Census-Data-Standardization-and-Analysis-Pipeline/main/census_2011%20(1).xlsx\"\n",
        "TELANGANA_DOCX_URL = \"https://raw.githubusercontent.com/bhuguvi26/Census-Data-Standardization-and-Analysis-Pipeline/main/Telangana%20(1).docx\"\n",
        "\n",
        "# MongoDB credentials\n",
        "MONGO_URI = \"mongodb+srv://bhuvan:12345@cluster0.obh30fm.mongodb.net/censusdb?retryWrites=true&w=majority\"\n",
        "MONGO_DB = \"censusdb\"\n",
        "MONGO_COLLECTION = \"census\"\n",
        "\n",
        "# SQLite database file\n",
        "SQLITE_DB = \"census.db\"\n",
        "FACTS_TABLE = \"census_clean\"\n",
        "\n",
        "# =============================\n",
        "# UTILITY FUNCTIONS\n",
        "# =============================\n",
        "def fetch_bytes(url: str) -> BytesIO:\n",
        "    resp = requests.get(url, timeout=60)\n",
        "    resp.raise_for_status()\n",
        "    return BytesIO(resp.content)\n",
        "\n",
        "def format_state_name(name: str) -> str:\n",
        "    if pd.isna(name): return name\n",
        "    name = str(name).replace(\"&\", \"and\")\n",
        "    words = name.split()\n",
        "    return \" \".join([w.capitalize() if w.lower() != \"and\" else \"and\" for w in words])\n",
        "\n",
        "def safe_rename_columns(df: pd.DataFrame, mapping: dict) -> pd.DataFrame:\n",
        "    existing = {k: v for k, v in mapping.items() if k in df.columns}\n",
        "    df = df.rename(columns=existing)\n",
        "    df.columns = [c[:60] for c in df.columns]  # <= 60 chars\n",
        "    return df\n",
        "\n",
        "def compute_missing_pct(df: pd.DataFrame) -> pd.Series:\n",
        "    return df.isna().mean().mul(100).round(2)\n",
        "\n",
        "def fill_from_sum(df: pd.DataFrame, target: str, parts: list):\n",
        "    if target not in df.columns: return\n",
        "    if not set(parts).issubset(df.columns): return\n",
        "    sum_series = df[parts].sum(axis=1, min_count=len(parts))\n",
        "    df[target] = df[target].fillna(sum_series)\n",
        "\n",
        "# =============================\n",
        "# DATA INGESTION\n",
        "# =============================\n",
        "excel_bytes = fetch_bytes(EXCEL_URL)\n",
        "docx_bytes  = fetch_bytes(TELANGANA_DOCX_URL)\n",
        "\n",
        "df = pd.read_excel(excel_bytes, engine=\"openpyxl\")\n",
        "telangana_doc = Document(docx_bytes)\n",
        "telangana_districts = [p.text.strip() for p in telangana_doc.paragraphs if p.text.strip()]\n",
        "\n",
        "# =============================\n",
        "# TASK 1: Rename Column Names\n",
        "# =============================\n",
        "rename_map = {\n",
        "    \"State name\": \"State_UT\",\n",
        "    \"District name\": \"District\",\n",
        "    \"Male_Literate\": \"Literate_Male\",\n",
        "    \"Female_Literate\": \"Literate_Female\",\n",
        "    \"Rural_Households\": \"Households_Rural\",\n",
        "    \"Urban_Households\": \"Households_Urban\",\n",
        "    \"Urban_ Households\": \"Households_Urban\",  # handle stray space\n",
        "    \"Age_Group_0_29\": \"Young_and_Adult\",\n",
        "    \"Age_Group_30_49\": \"Middle_Aged\",\n",
        "    \"Age_Group_50\": \"Senior_Citizen\",\n",
        "    \"Age not stated\": \"Age_Not_Stated\",\n",
        "}\n",
        "df = safe_rename_columns(df, rename_map)\n",
        "\n",
        "# =============================\n",
        "# TASK 2: Rename State/UT Names\n",
        "# =============================\n",
        "if \"State_UT\" in df.columns:\n",
        "    df[\"State_UT\"] = df[\"State_UT\"].apply(format_state_name)\n",
        "\n",
        "# =============================\n",
        "# TASK 3: New State/UT Formation\n",
        "# =============================\n",
        "# Telangana from Andhra Pradesh (2014)\n",
        "if {\"District\",\"State_UT\"}.issubset(df.columns):\n",
        "    df.loc[(df[\"District\"].isin(telangana_districts)) & (df[\"State_UT\"].str.strip().str.lower()==\"andhra pradesh\"), \"State_UT\"] = \"Telangana\"\n",
        "\n",
        "# Ladakh from Jammu and Kashmir (2019)\n",
        "ladakh_districts = [\"Leh\", \"Kargil\"]\n",
        "df.loc[(df[\"District\"].isin(ladakh_districts)) & (df[\"State_UT\"].str.strip().str.lower()==\"jammu and kashmir\"), \"State_UT\"] = \"Ladakh\"\n",
        "\n",
        "# =============================\n",
        "# TASK 4: Missing Data Handling\n",
        "# =============================\n",
        "missing_before = compute_missing_pct(df)\n",
        "fill_from_sum(df, \"Population\", [\"Male\", \"Female\"])\n",
        "fill_from_sum(df, \"Literate\", [\"Literate_Male\", \"Literate_Female\"])\n",
        "fill_from_sum(df, \"Population\", [\"Young_and_Adult\", \"Middle_Aged\", \"Senior_Citizen\", \"Age_Not_Stated\"])\n",
        "fill_from_sum(df, \"Households\", [\"Households_Rural\", \"Households_Urban\"])\n",
        "missing_after = compute_missing_pct(df)\n",
        "\n",
        "print(\"== Missing data BEFORE (%) ==\")\n",
        "print(missing_before)\n",
        "print(\"\\n== Missing data AFTER (%) ==\")\n",
        "print(missing_after)\n",
        "print(\"\\n== Sample of processed data ==\")\n",
        "print(df.head())\n",
        "\n",
        "# =============================\n",
        "# TASK 5: Save Data to MongoDB\n",
        "# =============================\n",
        "try:\n",
        "    mongo_client = MongoClient(MONGO_URI)\n",
        "    mongo_db = mongo_client[MONGO_DB]\n",
        "    mongo_coll = mongo_db[MONGO_COLLECTION]\n",
        "    # deterministic _id for upserts\n",
        "    if {\"State_UT\",\"District\"}.issubset(df.columns):\n",
        "        df[\"_id\"] = df[\"State_UT\"].astype(str).str.strip() + \"||\" + df[\"District\"].astype(str).str.strip()\n",
        "    else:\n",
        "        df[\"_id\"] = df.index.astype(str)\n",
        "    mongo_coll.delete_many({})\n",
        "    mongo_coll.insert_many(df.to_dict(orient=\"records\"))\n",
        "    print(\"‚úÖ Data uploaded to MongoDB successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå MongoDB upload failed:\", e)\n",
        "\n",
        "# =============================\n",
        "# TASK 6: Upload to SQLite with constraints\n",
        "# =============================\n",
        "conn = sqlite3.connect(SQLITE_DB)\n",
        "conn.execute(\"PRAGMA foreign_keys = ON;\")\n",
        "df.to_sql(FACTS_TABLE, conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "try:\n",
        "    # States dimension\n",
        "    conn.execute(\"\"\"CREATE TABLE IF NOT EXISTS states (State_UT TEXT PRIMARY KEY);\"\"\")\n",
        "    # Districts dim with FK\n",
        "    conn.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS districts (\n",
        "            District TEXT NOT NULL,\n",
        "            State_UT TEXT NOT NULL,\n",
        "            PRIMARY KEY(State_UT, District),\n",
        "            FOREIGN KEY(State_UT) REFERENCES states(State_UT)\n",
        "        );\n",
        "    \"\"\")\n",
        "    states = (pd.DataFrame({\"State_UT\": sorted(df[\"State_UT\"].dropna().unique())})\n",
        "              if \"State_UT\" in df.columns else pd.DataFrame({\"State_UT\": []}))\n",
        "    states.to_sql(\"states\", conn, if_exists=\"replace\", index=False)\n",
        "    districts = (df[[\"State_UT\",\"District\"]].drop_duplicates()\n",
        "                 if {\"State_UT\",\"District\"}.issubset(df.columns)\n",
        "                 else pd.DataFrame(columns=[\"State_UT\",\"District\"]))\n",
        "    districts.to_sql(\"districts\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "    # Enforce uniqueness on facts\n",
        "    conn.execute(f\"CREATE UNIQUE INDEX IF NOT EXISTS idx_{FACTS_TABLE}_state_district ON {FACTS_TABLE}(State_UT, District);\")\n",
        "    print(\"‚úÖ Data uploaded to SQLite with dimensions and constraints.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è SQLite constraint setup warning:\", e)\n",
        "\n",
        "# =============================\n",
        "# TASK 7: Streamlit Dashboard ‚Äî ALL QUERIES\n",
        "# =============================\n",
        "def get_available_columns(conn, table_name):\n",
        "    cols = pd.read_sql_query(f\"PRAGMA table_info({table_name});\", conn)[\"name\"].tolist()\n",
        "    return set(cols)\n",
        "\n",
        "def choose_sum_cols(available, candidates, alias_map=None):\n",
        "    exprs = []\n",
        "    for c in candidates:\n",
        "        if c in available:\n",
        "            alias = alias_map.get(c, c) if alias_map else c\n",
        "            exprs.append(f\"SUM(COALESCE({c},0)) AS {alias}\")\n",
        "    return exprs\n",
        "\n",
        "def run_dashboard():\n",
        "    st.title(\"üß≠ Census Data Analysis Dashboard (Colab)\")\n",
        "\n",
        "    conn = sqlite3.connect(SQLITE_DB)\n",
        "    available = get_available_columns(conn, FACTS_TABLE)\n",
        "\n",
        "    with st.expander(\"üîé Filters\"):\n",
        "        # Optional dropdown populated from DB\n",
        "        states_list = pd.read_sql_query(f\"SELECT DISTINCT State_UT FROM {FACTS_TABLE} ORDER BY State_UT;\", conn)[\"State_UT\"].tolist() if \"State_UT\" in available else [\"\"]\n",
        "        state_filter = st.selectbox(\"Filter by State/UT\", [\"\"] + states_list, index=0)\n",
        "        district_filter = st.text_input(\"Filter by District (optional)\")\n",
        "\n",
        "    clauses, params = [], []\n",
        "    if state_filter.strip(): clauses.append(\"State_UT = ?\"); params.append(state_filter.strip())\n",
        "    if district_filter.strip(): clauses.append(\"District = ?\"); params.append(district_filter.strip())\n",
        "    where_sql = (\" WHERE \" + \" AND \".join(clauses)) if clauses else \"\"\n",
        "\n",
        "    candidates = {\n",
        "        \"workers\": [\"Workers_Male\", \"Workers_Female\"],\n",
        "        \"lpg_png\": [\"Households_LPG_PNG\", \"Households_Cooking_LPG_PNG\"],\n",
        "        \"religion\": [\"Hindus\", \"Muslims\", \"Christians\", \"Sikhs\", \"Buddhists\", \"Jains\", \"Others_Religions\", \"Religion_Not_Stated\"],\n",
        "        \"internet\": [\"Households_Internet\", \"Households_Internet_Access\"],\n",
        "        \"education\": [\"Below_Primary\",\"Primary\",\"Middle\",\"Secondary\",\"Higher_Secondary\",\"Graduate\",\"Post_Graduate\",\"Literates\",\"Illiterates\"],\n",
        "        \"transport_media\": [\"Households_Bicycle\",\"Households_Car\",\"Households_Radio\",\"Households_Television\",\"Households_Two_Wheeler\",\"Households_Computer\",\"Households_Mobile\"],\n",
        "        \"house_conditions\": [\"Houses_Dilapidated\",\"Houses_Separate_Kitchen\",\"Houses_Bathing_Facility\",\"Houses_Latrine_Facility\"],\n",
        "        \"hh_size\": [\"HH_Size_1\",\"HH_Size_2\",\"HH_Size_3_to_5\",\"HH_Size_6_to_8\",\"HH_Size_9_plus\"],\n",
        "        \"latrine_within\": [\"Households_Latrine_Within\",\"Households_Latrine_Within_Premises\"],\n",
        "        \"tenure\": [\"Households_Owned\",\"Households_Rented\"],\n",
        "        \"latrine_types\": [\"Latrine_Pit\",\"Latrine_Flush\",\"Latrine_Others\"],\n",
        "        \"water_near\": [\"Households_Water_Near\",\"Households_Drinking_Water_Near\"],\n",
        "        \"power_parity\": [\n",
        "            \"Power_Parity_Rs_330000_425000\",\n",
        "            \"Power_Parity_Rs_425000_545000\",\n",
        "            \"Power_Parity_Rs_330000_545000\",\n",
        "            \"Power_Parity_Above_Rs_545000\",\n",
        "            \"Total_Power_Parity\"\n",
        "        ],\n",
        "        \"married_couples\": [\"Married_Couples_Size_1\",\"Married_Couples_Size_2\",\"Married_Couples_Size_3_to_5\",\"Married_Couples_Size_6_plus\"],\n",
        "        \"bpl\": [\"BPL_Households\",\"Households_Below_Poverty_Line\"]\n",
        "    }\n",
        "\n",
        "    labels = [\n",
        "        \"Total population of each district\",\n",
        "        \"Literate males and females in each district\",\n",
        "        \"Percentage of workers (male + female) in each district\",\n",
        "        \"Households with LPG/PNG as cooking fuel in each district\",\n",
        "        \"Religious composition of each district\",\n",
        "        \"Households with internet access in each district\",\n",
        "        \"Educational attainment distribution in each district\",\n",
        "        \"Households with transport/media assets (bicycle, car, radio, TV, etc.) in each district\",\n",
        "        \"Condition of occupied census houses (kitchen, bath, latrine, dilapidated) in each district\",\n",
        "        \"Household size distribution in each district\",\n",
        "        \"Total number of households in each state\",\n",
        "        \"Households with latrine facility within premises in each state\",\n",
        "        \"Average household size in each state\",\n",
        "        \"Owned vs rented households in each state\",\n",
        "        \"Distribution of latrine types in each state\",\n",
        "        \"Households with drinking water sources near premises in each state\",\n",
        "        \"Average household income distribution (Power Parity) in each state\",\n",
        "        \"Percentage of married couples by household size in each state\",\n",
        "        \"Households below the poverty line in each state (Power Parity/BPL)\",\n",
        "        \"Overall literacy rate (percentage of literate population) in each state\"\n",
        "    ]\n",
        "    selected = st.selectbox(\"üìå Select a query\", labels)\n",
        "\n",
        "    if selected == \"Total population of each district\":\n",
        "        population_expr = \"COALESCE(Population, COALESCE(Male,0)+COALESCE(Female,0))\"\n",
        "        q = f\"SELECT District, SUM({population_expr}) AS Total_Population FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Literate males and females in each district\":\n",
        "        exprs = choose_sum_cols(available, [\"Literate_Male\",\"Literate_Female\"])\n",
        "        select_sql = \", \".join([\"District\"] + (exprs or [\"SUM(0) AS Literate_Male\",\"SUM(0) AS Literate_Female\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Percentage of workers (male + female) in each district\":\n",
        "        workers_expr = \"+\".join([f\"COALESCE({c},0)\" for c in candidates[\"workers\"] if c in available]) or \"NULL\"\n",
        "        population_expr = \"COALESCE(Population, COALESCE(Male,0)+COALESCE(Female,0))\"\n",
        "        q = f\"\"\"SELECT District,\n",
        "                       CASE WHEN SUM({population_expr})>0 AND {workers_expr} IS NOT NULL\n",
        "                            THEN ROUND(100.0 * SUM({workers_expr}) / SUM({population_expr}), 2)\n",
        "                            ELSE NULL END AS Workers_Percentage\n",
        "                FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\"\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Households with LPG/PNG as cooking fuel in each district\":\n",
        "        exprs = choose_sum_cols(available, candidates[\"lpg_png\"], alias_map={\"Households_Cooking_LPG_PNG\":\"Households_LPG_PNG\"})\n",
        "        select_sql = \", \".join([\"District\"] + (exprs or [\"SUM(0) AS Households_LPG_PNG\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Religious composition of each district\":\n",
        "        exprs = choose_sum_cols(available, candidates[\"religion\"])\n",
        "        select_sql = \", \".join([\"District\"] + (exprs or [\"SUM(0) AS No_Religion_Columns\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Households with internet access in each district\":\n",
        "        exprs = choose_sum_cols(available, candidates[\"internet\"])\n",
        "        select_sql = \", \".join([\"District\"] + (exprs or [\"SUM(0) AS Households_Internet\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Educational attainment distribution in each district\":\n",
        "        exprs = choose_sum_cols(available, candidates[\"education\"])\n",
        "        select_sql = \", \".join([\"District\"] + (exprs or [\"SUM(0) AS Education_Data\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Households with transport/media assets (bicycle, car, radio, TV, etc.) in each district\":\n",
        "        exprs = choose_sum_cols(available, candidates[\"transport_media\"])\n",
        "        select_sql = \", \".join([\"District\"] + (exprs or [\"SUM(0) AS Transport_Media\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Condition of occupied census houses (kitchen, bath, latrine, dilapidated) in each district\":\n",
        "        exprs = choose_sum_cols(available, candidates[\"house_conditions\"])\n",
        "        select_sql = \", \".join([\"District\"] + (exprs or [\"SUM(0) AS House_Conditions\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Household size distribution in each district\":\n",
        "        exprs = choose_sum_cols(available, candidates[\"hh_size\"])\n",
        "        select_sql = \", \".join([\"District\"] + (exprs or [\"SUM(0) AS HH_Size\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY District ORDER BY District;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Total number of households in each state\":\n",
        "        households_expr = \"COALESCE(Households, COALESCE(Households_Rural,0)+COALESCE(Households_Urban,0))\"\n",
        "        q = f\"SELECT State_UT, SUM({households_expr}) AS Total_Households FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Households with latrine facility within premises in each state\":\n",
        "        exprs = choose_sum_cols(available, candidates[\"latrine_within\"], alias_map={\"Households_Latrine_Within_Premises\":\"Households_Latrine_Within\"})\n",
        "        select_sql = \", \".join([\"State_UT\"] + (exprs or [\"SUM(0) AS Households_Latrine_Within\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Average household size in each state\":\n",
        "        households_expr = \"COALESCE(Households, COALESCE(Households_Rural,0)+COALESCE(Households_Urban,0))\"\n",
        "        population_expr = \"COALESCE(Population, COALESCE(Male,0)+COALESCE(Female,0))\"\n",
        "        q = f\"\"\"SELECT State_UT,\n",
        "                       CASE WHEN SUM({households_expr})>0\n",
        "                            THEN ROUND(1.0 * SUM({population_expr}) / SUM({households_expr}), 2)\n",
        "                            ELSE NULL END AS Avg_HH_Size\n",
        "                FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\"\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Owned vs rented households in each state\":\n",
        "        exprs = choose_sum_cols(available, [\"Households_Owned\",\"Households_Rented\"])\n",
        "        select_sql = \", \".join([\"State_UT\"] + (exprs or [\"SUM(0) AS Owned\",\"SUM(0) AS Rented\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Distribution of latrine types in each state\":\n",
        "        exprs = choose_sum_cols(available, [\"Latrine_Pit\",\"Latrine_Flush\",\"Latrine_Others\"])\n",
        "        select_sql = \", \".join([\"State_UT\"] + (exprs or [\"SUM(0) AS Latrine_Types\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Households with drinking water sources near premises in each state\":\n",
        "        exprs = choose_sum_cols(available, [\"Households_Water_Near\",\"Households_Drinking_Water_Near\"])\n",
        "        select_sql = \", \".join([\"State_UT\"] + (exprs or [\"SUM(0) AS Water_Near\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Average household income distribution (Power Parity) in each state\":\n",
        "        exprs = choose_sum_cols(available, [\n",
        "            \"Power_Parity_Rs_330000_425000\",\n",
        "            \"Power_Parity_Rs_425000_545000\",\n",
        "            \"Power_Parity_Rs_330000_545000\",\n",
        "            \"Power_Parity_Above_Rs_545000\",\n",
        "            \"Total_Power_Parity\"\n",
        "        ])\n",
        "        select_sql = \", \".join([\"State_UT\"] + (exprs or [\"SUM(0) AS Power_Parity\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Percentage of married couples by household size in each state\":\n",
        "        couples_cols = [c for c in [\"Married_Couples_Size_1\",\"Married_Couples_Size_2\",\"Married_Couples_Size_3_to_5\",\"Married_Couples_Size_6_plus\"] if c in available]\n",
        "        base_sum = \"+\".join([f\"COALESCE({c},0)\" for c in couples_cols]) or \"NULL\"\n",
        "        parts = [\"State_UT\"]\n",
        "        if couples_cols:\n",
        "            for c in couples_cols:\n",
        "                parts.append(f\"CASE WHEN SUM({base_sum})>0 THEN ROUND(100.0 * SUM(COALESCE({c},0)) / SUM({base_sum}),2) ELSE NULL END AS {c}_Pct\")\n",
        "        else:\n",
        "            parts.append(\"NULL AS Married_Couples_Pct\")\n",
        "        select_sql = \", \".join(parts)\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Households below the poverty line in each state (Power Parity/BPL)\":\n",
        "        exprs = choose_sum_cols(available, [\"BPL_Households\",\"Households_Below_Poverty_Line\"])\n",
        "        select_sql = \", \".join([\"State_UT\"] + (exprs or [\"SUM(0) AS BPL_Households\"]))\n",
        "        q = f\"SELECT {select_sql} FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    elif selected == \"Overall literacy rate (percentage of literate population) in each state\":\n",
        "        literate_expr = \"COALESCE(Literate, COALESCE(Literate_Male,0)+COALESCE(Literate_Female,0))\"\n",
        "        population_expr = \"COALESCE(Population, COALESCE(Male,0)+COALESCE(Female,0))\"\n",
        "        q = f\"\"\"SELECT State_UT,\n",
        "                       CASE WHEN SUM({population_expr}) > 0\n",
        "                            THEN ROUND(100.0 * SUM({literate_expr}) / SUM({population_expr}), 2)\n",
        "                            ELSE NULL END AS Literacy_Rate_Percent\n",
        "                FROM {FACTS_TABLE}{where_sql} GROUP BY State_UT ORDER BY State_UT;\"\"\"\n",
        "        df_res = pd.read_sql_query(q, conn, params=params)\n",
        "\n",
        "    else:\n",
        "        df_res = pd.DataFrame()\n",
        "\n",
        "    st.subheader(\"Results\")\n",
        "    if df_res.empty:\n",
        "        st.info(\"No results or columns missing for this query.\")\n",
        "    else:\n",
        "        st.dataframe(df_res)\n",
        "\n",
        "    if not df_res.empty:\n",
        "        st.download_button(\n",
        "            \"Download results as CSV\",\n",
        "            df_res.to_csv(index=False),\n",
        "            file_name=f\"{selected.replace(' ','_')}.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "# Run dashboard when script executed by Streamlit\n",
        "run_dashboard()\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# 4) Start Streamlit in the background (port 8501)\n",
        "import os, subprocess, time, re\n",
        "os.environ[\"STREAMLIT_SERVER_PORT\"] = \"8501\"\n",
        "streamlit_proc = subprocess.Popen([\"streamlit\", \"run\", \"app.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# 5) Start Cloudflared tunnel to expose the Streamlit server\n",
        "cloudflared_proc = subprocess.Popen([\"./cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8501\", \"--no-autoupdate\"],\n",
        "                                    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "print(\"‚è≥ Starting Streamlit & Cloudflared...\")\n",
        "public_url = None\n",
        "start_time = time.time()\n",
        "while time.time() - start_time < 60:  # wait up to 60 seconds\n",
        "    line = cloudflared_proc.stdout.readline()\n",
        "    if not line:\n",
        "        time.sleep(0.5)\n",
        "        continue\n",
        "    m = re.search(r'https://[-\\w\\.]+\\.trycloudflare\\.com', line)\n",
        "    if m:\n",
        "        public_url = m.group(0)\n",
        "        break\n",
        "\n",
        "if public_url:\n",
        "    print(\"üåê Public URL:\", public_url)\n",
        "    print(\"‚úÖ Open this URL to view the Streamlit dashboard.\")\n",
        "else:\n",
        "    print(\"‚ùå Could not obtain public URL from Cloudflared logs. Scroll up to see log output.\")\n",
        "    print(\"Tip: Re-run the cell; sometimes Cloudflared takes a moment to provision the URL.\")\n",
        "\n",
        "print(\"‚ÑπÔ∏è To stop: Runtime ‚Üí Interrupt execution, or run:\")\n",
        "print(\"    streamlit_proc.terminate(); cloudflared_proc.terminate()\")\n"
      ]
    }
  ]
}